{
  "workflow": {
    "name": "CUDA vs NPU vs CPU Performance Test",
    "description": "Compares CUDA RTX 5090, Intel NPU, and CPU inference performance",
    "settings": {
      "max_parallel_nodes": 4
    }
  },
  
  "nodes": [
    {
      "id": "download_model",
      "function": "workflow_nodes.download_model_node.download_model_node",
      "depends_on": [],
      "inputs": {
        "model_name": "yolov8s.onnx",
        "models_dir": "models"
      }
    },
    
    {
      "id": "load_image",
      "function": "workflow_nodes.load_image_node.load_image_node",
      "depends_on": [],
      "inputs": {
        "image_path": "input/soccer.jpg",
        "session_namespace": "image"
      }
    },
    
    {
      "id": "cuda_model",
      "function": "workflow_nodes.load_cuda_model_node.load_cuda_model_node",
      "depends_on": ["download_model"],
      "inputs": {
        "model_path": "models/yolov8s.onnx",
        "device_id": 0
      }
    },
    
    {
      "id": "cpu_model", 
      "function": "workflow_nodes.load_cpu_model_node.load_cpu_model_node",
      "depends_on": ["download_model"],
      "inputs": {
        "model_path": "models/yolov8s.onnx"
      }
    },
    
    {
      "id": "npu_model",
      "function": "workflow_nodes.load_openvino_model_node.load_openvino_model_node",
      "depends_on": ["download_model"],
      "inputs": {
        "model_path": "models/yolov8s.onnx",
        "device": "NPU"
      }
    },
    
    {
      "id": "cuda_inference",
      "function": "workflow_nodes.cuda_inference_node.cuda_inference_node",
      "depends_on": ["load_image", "cuda_model"],
      "inputs": {
        "confidence_threshold": 0.25,
        "iterations": 50
      }
    },
    
    {
      "id": "cpu_inference",
      "function": "workflow_nodes.cpu_inference_node.cpu_inference_node", 
      "depends_on": ["load_image", "cpu_model"],
      "inputs": {
        "confidence_threshold": 0.25,
        "iterations": 50
      }
    },
    
    {
      "id": "npu_inference",
      "function": "workflow_nodes.npu_inference_node.npu_inference_node",
      "depends_on": ["load_image", "npu_model"],
      "inputs": {
        "confidence_threshold": 0.25,
        "iterations": 50
      }
    },
    
    {
      "id": "compare_performance",
      "function": "workflow_nodes.performance_stats_node.performance_stats_node",
      "depends_on": ["cuda_inference", "cpu_inference", "npu_inference"],
      "inputs": {
        "cuda_result": "$cuda_inference",
        "cpu_result": "$cpu_inference",
        "npu_result": "$npu_inference"
      }
    }
  ]
}
